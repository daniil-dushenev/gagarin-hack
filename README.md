# :trophy: Гагарин.Хак - Sentiment Analysis и NER для новостей о фондовом рынке MOEX
## ❓ Задача
Нам предстояло разработать модель, которая будет предсказывать сентиментальность новостей о каких-то компаниях рынка акций. При этом стоило учитывать о какой компании из новости мы смотрим сентимантальность. Именно на этом кейсодержатели просили акцентировать внимание. Также нужно было разработать NER алгоритм, который будет вытаскивать названия компаний из новости. Проблемой стало именно соотнесение синонимов названий компании (сбер, сбербанк, ПАО СБЕРБАНК).

### :tada: Результат
#### :trophy: Место: **4/40 место**</br>
**Score:** </br>
Accuracy: **0.67**</br>
Метрики классификации по классам:
</br></br>
![image](https://github.com/daniil-dushenev/gagarin-hack/assets/44606552/5d71a43e-8805-4f61-bb37-a947b5c0916c)
</br></br>
### :page_facing_up: Данные
Подготовили неплохой размеченный датасет новостей, всего 5 классов (1-5). Также был подготовлен датасет для NER алгоритма. К сожалению, были ошибки в данных.
</br></br>
### :memo: Решение: NER
Конечно же мы пробовали использовать BERT-like модели, которые спокойно вытаскивали названия компаний из текста. Однако 1) это не решеает проблему с синонимами, описанную выше. 2) это долго, кейсодержатели поставили жесткие рамки в скорости работы алгоритма. В итоге мы пришли к простой идее: полный перебор всех слов текста и поиск по хеш-таблице полного названия. Таким образом: мы можем пополнять словарь синонимов, при этом компаний ограниченное количество на MOEX. При этом, добились алгоритмической сложности O(n).
</br></br>
### :memo: Sentiment Analysis: Baseline
**Модель:** cointegrated/rubert-tiny-sentiment-balanced </br>
Finetune на текстах из исходного датасета на нормализированном тексте. </br>
**Accuracy:** 0.57 </br>
Пример входного текста: Акции Яндекса подорожали на Московской бирже
</br></br>
### :memo: Sentiment Analysis: SEP Token
**Модель:** seara/rubert-tiny2-russian-sentiment </br>
Finetune на текстах из исходного датасета на нормализированном тексте. В этот раз встраивали название компании, на которую нужно обратить внимание, в начало текста вместе с токеном сепарации, обучали на таких текстах. В итоге модель начала понимать о какой компании идет речь в тексте и значительно улучшило показатели.</br>
**Accuracy:** 0.65 </br>
Пример входного текста: Яндекс[SEP]Акции Яндекса подорожали на Московской бирже
</br></br>
### :memo: Sentiment Analysis: Special Token
**Модель:** seara/rubert-tiny2-russian-sentiment </br>
Finetune на текстах из исходного датасета на нормализированном тексте. Теперь, вместо всех упоминаний о нужной нам компании, мы вставляли специальный новый токен [COMPANY]. Модель с помощью него не только понимала о какой компании нужно проводить сентимент анализ, но и осознавала, в какой части текста находится текст о нужной нам компании. В итоге эта идея оказалась лучше предыдущей. В теории, можно попробовать делать токен [COMPANY] с каким-нибудь эмбеддингом, хранящим информацию о нужной нам компании, но не успели это осуществить.</br>
**Accuracy:** 0.67 </br>
Пример входного текста: Акции [COMPANY] подорожали на Московской бирже
</br></br>
### :racing_car: Ускорение модели
Как я уже писал, нас сильно ограничили во времени работы модели, поэтому нужно было что-то делать со скоростью. Получилось квантизировать модель, что дало 1) меньший объем занимаемой памяти, 2) бОльшую скорость инференса.
</br></br>
### :bulb: Идеи для развития: Дистилляция
Также ооочень хотелось попробовать дистилляцию из bert-large в bert-tiny, однако не хватило времени и вычислительных мощностей. Прогнозировали существенный рост качества при хорошей скорости инференса.
